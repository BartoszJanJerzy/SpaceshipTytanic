{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for best hyperparameters set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather('./data/train_processed.ftr')\n",
    "val_df = pd.read_feather('./data/val_processed.ftr')\n",
    "cols = list(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare LGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[cols[:-1]].to_numpy()\n",
    "train_y = train_df[cols[-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = val_df[cols[:-1]].to_numpy()\n",
    "val_y = val_df[cols[-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    \n",
    "    def __init__(self, params, train_x, train_y, val_x, val_y):\n",
    "        self.params = params\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.val_x = val_x\n",
    "        self.val_y = val_y\n",
    "        \n",
    "        self.model = self.train_model()\n",
    "        self.y_pred_bin = self.get_bin_predictions()\n",
    "            \n",
    "    def train_model(self):\n",
    "        # 1 - Run model\n",
    "        model = lgb.LGBMClassifier(\n",
    "            boosting=self.params['boosting'],\n",
    "            n_estimators=self.params['num_rounds'],\n",
    "            max_depth=self.params['max_depth'],\n",
    "            learnig_rate=self.params['learning_rate'],\n",
    "            num_leaves = self.params['num_leaves'],\n",
    "            min_child_samples = self.params['min_data_in_leaf'],\n",
    "            subsample=self.params['bagging_fraction'],\n",
    "            reg_alpha=self.params['lambda_l1'],\n",
    "            reg_lambda=self.params['lambda_l2']\n",
    "        )\n",
    "        model.fit(train_x, train_y)\n",
    "        return model\n",
    "    \n",
    "    def get_bin_predictions(self):\n",
    "        # 2 - Get predictions\n",
    "        y_pred = self.model.predict(val_x)\n",
    "        y_pred_bin = [1 if y >= 0.5 else 0 for y in y_pred]\n",
    "        \n",
    "        return y_pred_bin\n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        return round(accuracy_score(self.val_y, self.y_pred_bin), 3)\n",
    "    \n",
    "    def get_class_report(self):\n",
    "        return classification_report(self.val_y, self.y_pred_bin)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 0 - Prepare params\n",
    "    num_rounds = trial.suggest_int(\"num_rounds\", 10, 100)\n",
    "    boosting = trial.suggest_categorical('boosting', ['gbdt', 'dart'])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.5)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 100)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 2, 100)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 500)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.9, 1.)\n",
    "    extra_trees = trial.suggest_categorical('extra_trees', [True, False])\n",
    "    lambda_l1 = trial.suggest_float('lambda_l1', 0, 0.1)\n",
    "    lambda_l2 = trial.suggest_float('lambda_l2', 0, 0.1)\n",
    "    \n",
    "    params = {\n",
    "        'num_rounds': num_rounds,\n",
    "        'objectives':'binary',\n",
    "        'verbosity':0,\n",
    "        'boosting':boosting,\n",
    "        'learning_rate':learning_rate,\n",
    "        'max_depth':max_depth,\n",
    "        'num_leaves':num_leaves,\n",
    "        'min_data_in_leaf':min_data_in_leaf,\n",
    "        'bagging_fraction':bagging_fraction,\n",
    "        'extra_trees':extra_trees,\n",
    "        'lambda_l1':lambda_l1,\n",
    "        'lambda_l2':lambda_l2\n",
    "    }\n",
    "    \n",
    "    # 1 - Model\n",
    "    model_tester = ModelTester(params, train_x, train_y, val_x, val_y)\n",
    "    acc = model_tester.get_accuracy()\n",
    "    error = 1 - acc\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_params = ['num_leaves', 'min_data_in_leaf', 'num_rounds', 'learning_rate', 'max_depth']\n",
    "plot_slice(study, params = key_params).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "'num_rounds': 89,\n",
    "'boosting': 'gbdt',\n",
    "'learning_rate': 0.19673057125087745,\n",
    "'max_depth': 88,\n",
    "'num_leaves': 8,\n",
    "'min_data_in_leaf': 37,\n",
    "'bagging_fraction': 0.9514661346499478,\n",
    "'extra_trees': False,\n",
    "'lambda_l1': 0.08212421594574758,\n",
    "'lambda_l2': 0.0021191892176790073\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(\n",
    "    boosting=best_params['boosting'],\n",
    "    n_estimators=best_params['num_rounds'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learnig_rate=best_params['learning_rate'],\n",
    "    num_leaves=best_params['num_leaves'],\n",
    "    min_child_samples=best_params['min_data_in_leaf'],\n",
    "    subsample=best_params['bagging_fraction'],\n",
    "    reg_alpha=best_params['lambda_l1'],\n",
    "    reg_lambda=best_params['lambda_l2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((train_x, val_x))\n",
    "y = np.concatenate((train_y, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(model, X, y, cv=10)\n",
    "print(f'Mean cv (k=10) accuracy score = {round(np.mean(cv_scores), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446da764",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266cb2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cat_col = {\n",
    "    'is_g734s': True,\n",
    "    'CryoSleep': True,\n",
    "    'VIP': True,\n",
    "    'Europa': True,\n",
    "    'Mars': True,\n",
    "    'PSO J318.5-22': True,\n",
    "    'TRAPPIST-1e': True,\n",
    "    'Age': False,\n",
    "    'RoomService': False,\n",
    "    'FoodCourt': False,\n",
    "    'ShoppingMall': False,\n",
    "    'Spa': False,\n",
    "    'VRDeck': False,\n",
    "    'segment': True\n",
    " }\n",
    "\n",
    "feature_mi = mutual_info_classif(X, y, discrete_features=list(is_cat_col.values()))\n",
    "feature_f = f_classif(X, y)\n",
    "\n",
    "feature_df = pd.DataFrame({\n",
    "    'feature': cols[:-1],\n",
    "    'mi': feature_mi,\n",
    "    'f': feature_f[0]\n",
    "})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_df[['mi_z', 'f_z']] = scaler.fit_transform(feature_df[['mi', 'f']])\n",
    "feature_df['feature_quality'] = feature_df[['mi_z', 'f_z']].mean(axis=1)\n",
    "\n",
    "feature_df.sort_values('feature_quality', ascending=False, inplace=True)\n",
    "best_features = feature_df['feature'].to_list()\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa982c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feature_df, x='feature_quality', y='feature')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cols = []\n",
    "cv_list = []\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    boosting=best_params['boosting'],\n",
    "    n_estimators=best_params['num_rounds'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learnig_rate=best_params['learning_rate'],\n",
    "    num_leaves=best_params['num_leaves'],\n",
    "    min_child_samples=best_params['min_data_in_leaf'],\n",
    "    subsample=best_params['bagging_fraction'],\n",
    "    reg_alpha=best_params['lambda_l1'],\n",
    "    reg_lambda=best_params['lambda_l2']\n",
    ")\n",
    "\n",
    "for feature in best_features:\n",
    "    temp_cols.append(feature)\n",
    "    X = pd.concat([train_df[temp_cols], val_df[temp_cols]]).to_numpy()\n",
    "    cv_score = cross_val_score(model, X, y, cv=10)\n",
    "    cv_list.append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for scores in cv_list:\n",
    "    means.append(round(np.mean(scores), 3))\n",
    "\n",
    "i_features = 0\n",
    "for i in range(len(means)):\n",
    "    if means[i] == max(means):\n",
    "        i_features = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5f89f",
   "metadata": {},
   "source": [
    "# Make final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[best_features[:i_features+1]].to_numpy()\n",
    "val_x = val_df[best_features[:i_features+1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae51d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(\n",
    "    boosting=best_params['boosting'],\n",
    "    n_estimators=best_params['num_rounds'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learnig_rate=best_params['learning_rate'],\n",
    "    num_leaves=best_params['num_leaves'],\n",
    "    min_child_samples=best_params['min_data_in_leaf'],\n",
    "    subsample=best_params['bagging_fraction'],\n",
    "    reg_alpha=best_params['lambda_l1'],\n",
    "    reg_lambda=best_params['lambda_l2']\n",
    ")\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "pred_val = model.predict_proba(val_x)\n",
    "pred_train = model.predict_proba(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'model': model,\n",
    "    'features': best_features\n",
    "}\n",
    "\n",
    "filepath = os.path.join('models', 'lgbm.pickle')\n",
    "with open(filepath, 'wb') as file:\n",
    "    pickle.dump(model_dict, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f28e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba_df = pd.DataFrame(pred_train)\n",
    "train_proba_df.columns = ['0', 'lgbm']\n",
    "train_proba_df['y'] = train_y.astype(int)\n",
    "train_proba_df.drop(columns='0', inplace=True)\n",
    "train_proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80afdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba_df = pd.DataFrame(pred_val)\n",
    "val_proba_df.columns = ['0', 'lgbm']\n",
    "val_proba_df['y'] = val_y.astype(int)\n",
    "val_proba_df.drop(columns='0', inplace=True)\n",
    "val_proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed329f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba_final = pd.read_csv('./data/ensemble_train_df.csv')\n",
    "train_proba_final['lgbm'] = train_proba_df['lgbm']\n",
    "val_proba_final = pd.read_csv('./data/ensemble_val_df.csv')\n",
    "val_proba_final['lgbm'] = val_proba_df['lgbm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88113346",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba_final = train_proba_final[['ada_boost', 'svc', 'lgbm', 'y']]\n",
    "train_proba_final.to_feather('./data/ensemble_train_df.ftr')\n",
    "val_proba_final = val_proba_final[['ada_boost', 'svc', 'lgbm', 'y']]\n",
    "val_proba_final.to_feather('./data/ensemble_val_df.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b91f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('models', 'lgbm.pickle')\n",
    "pickle.dump(model, open(filepath, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a74854dbd35b3b1e1641f2d717929c6b738adcdd3262c03fe72ebc0e6c9a894"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
